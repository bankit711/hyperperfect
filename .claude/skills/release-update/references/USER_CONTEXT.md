# User Context

Who HyperPerfect users are and how to communicate with them.
Reference this whenever writing changelog entries, emails, or help content.

## Who They Are

Excel power users — finance, FP&A, analysts, operations. Comfortable with spreadsheets and data. Not AI experts.

They understand concepts when explained plainly. They do not know the vocabulary:
- Don't know what "Haiku", "Opus", "Sonnet" mean
- Don't know what "tokens" are
- Don't know what a "context window" is (but understand "memory" immediately)
- Don't know what "subagents" means (explain as "a team of AI assistants" or "specialists working in parallel")
- Don't know what "LLM", "inference", or "routing" mean

They tend to:
- Pick one mode and stick with it because too many options feel overwhelming
- Not know when to switch models or why it would help
- Hit memory limits and not understand what happened
- Be impressed by outcomes, not by technology

## Communication Principles

**Use their vocabulary, not ours:**
- "Memory" not "context window"
- "AI memory indicator" or "memory bar" not "token counter"
- "Picks the right model" not "routes to optimal inference parameters"
- "Team of AI specialists" not "subagents"
- Skip model names entirely unless absolutely necessary (and if needed: "our fast model" / "our most powerful model")

**Lead with the outcome:**
They don't care how it works. They care what it does for them.
Bad: "A Haiku-based classifier routes each message to the optimal model and effort level."
Good: "HyperPerfect picks the right AI for each request — fast answers stay fast, complex work gets full power."

**Explain concepts the first time, then use plain shorthand:**
If we need to reference memory limits: explain once in the help page, then use "memory" consistently.

## What They Care About

- Getting accurate, usable Excel work done faster
- Not burning credits on simple tasks
- Not having sessions interrupted (memory limits, mode confusion)
- Feeling like the tool is working *for* them, not requiring configuration from them
- Results that are explainable and auditable (they have to defend their work)

## What They Don't Care About

- Which model is running under the hood
- Token counts or context window sizes
- The names of AI techniques being used
- Infrastructure or engineering details
